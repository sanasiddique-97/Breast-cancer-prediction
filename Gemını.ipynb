{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4d175-54d7-4f50-af3c-86e868674d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "# Import machine learning and image processing libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Google Generative AI library for Gemini 1.5 API\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import caching\n",
    "\n",
    "# Kaggle secrets for API access\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Load Kaggle secrets to access the AI Studio token\n",
    "user_secrets = UserSecretsClient()\n",
    "ai_studio_token = user_secrets.get_secret(\"gemini_token\")\n",
    "\n",
    "# Authenticate Google Generative AI API with the AI Studio token\n",
    "genai.configure(api_key=ai_studio_token)\n",
    "\n",
    "# Check if TensorFlow is using GPU for faster computation\n",
    "print(\"TensorFlow is using GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"Packages imported and AI Studio token configured successfully!\")\n",
    "\n",
    "\n",
    "# Define the configuration for the Gemini 1.5 model generation\n",
    "generation_config = {\n",
    "    \"temperature\": 1,           # Controls the randomness of outputs. Higher values mean more random outputs.\n",
    "    \"top_p\": 0.95,              # Nucleus sampling threshold for sampling diversity.\n",
    "    \"top_k\": 64,                # Number of top probable tokens considered for sampling.\n",
    "    \"max_output_tokens\": 8192,  # Maximum number of tokens the model will output.\n",
    "    \"response_mime_type\": \"text/plain\",  # MIME type for the output format.\n",
    "}\n",
    "\n",
    "# Create and load the Gemini 1.5 model using the above configuration\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "print(\"gemini-1.5-flash model loaded successfully!\")\n",
    "\n",
    "# Define the directories\n",
    "benign_dir = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/\"\n",
    "malignant_dir = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/\"\n",
    "normal_dir = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/\"\n",
    "\n",
    "# Function to create a video from images\n",
    "def create_video_from_images(image_dir, video_name, num_images=10, fps=1):\n",
    "    image_paths = [\n",
    "        os.path.join(image_dir, f) for f in os.listdir(image_dir) \n",
    "        if f.endswith('.png') and \"_mask\" not in f\n",
    "    ]\n",
    "    random.shuffle(image_paths)\n",
    "    selected_images = image_paths[:num_images]  # Select the first 'num_images'\n",
    "\n",
    "    # Get the size of the first image to use for the video resolution\n",
    "    first_image = cv2.imread(selected_images[0])\n",
    "    height, width, layers = first_image.shape\n",
    "\n",
    "    # Initialize video writer with original image size\n",
    "    video_writer = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for path in selected_images:\n",
    "        image = cv2.imread(path)\n",
    "        video_writer.write(image)\n",
    "\n",
    "    video_writer.release()  # Finalize the video file\n",
    "\n",
    "# Define paths and create the video for each class\n",
    "benign_dir = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/'\n",
    "malignant_dir = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/'\n",
    "normal_dir = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/'\n",
    "\n",
    "# Create videos for each category without resizing\n",
    "create_video_from_images(benign_dir, \"benign_video.mp4\", num_images=50)\n",
    "create_video_from_images(malignant_dir, \"malignant_video.mp4\", num_images=50)\n",
    "create_video_from_images(normal_dir, \"normal_video.mp4\", num_images=50)\n",
    "\n",
    "# Now upload the videos to Gemini\n",
    "benign_video = genai.upload_file(\"benign_video.mp4\")\n",
    "malignant_video = genai.upload_file(\"malignant_video.mp4\")\n",
    "normal_video = genai.upload_file(\"normal_video.mp4\")\n",
    "example_prompt = (\n",
    "    \"I have provided videos of breast ultrasound images to guide your classification. \"\n",
    "    \"Please analyze and classify the following videos based on their characteristics:\\n\\n\"\n",
    "    f\"Benign Video: {benign_video}\\n\"\n",
    "    \"This video contains images that typically feature well-defined, smooth borders and homogeneous echogenicity, suggesting the absence of malignant characteristics.\\n\\n\"\n",
    "    f\"Malignant Video: {malignant_video}\\n\"\n",
    "    \"This video contains images that may display irregular borders, heterogeneous echogenicity, hypoechoic regions, or spiculated masses, which are potential indicators of malignancy. \"\n",
    "    \"You may also observe posterior acoustic shadowing or calcifications, which further support the suspicion of a tumor.\\n\\n\"\n",
    "    f\"Normal Video: {normal_video}\\n\"\n",
    "    \"This video contains images demonstrating typical breast tissue architecture, with uniform echogenicity, no visible masses, and no signs of architectural distortion or abnormal structures.\\n\"\n",
    ")\n",
    "\n",
    "# Define the path to the folder containing normal images\n",
    "folder_path = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/\"\n",
    "\n",
    "# Get a list of image files in the folder, excluding those with '_mask' in the filename\n",
    "image_files = [\n",
    "    os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "    if f.endswith('.png') and \"_mask\" not in f\n",
    "]\n",
    "\n",
    "# Pick 5 random images from the filtered list\n",
    "selected_images = np.random.choice(image_files, 10, replace=False)\n",
    "\n",
    "# Upload each selected image to Gemini 1.5 model and print the results\n",
    "for img_path in selected_images:\n",
    "    print(f\"===============================\")\n",
    "    print(f\"        Processing Image        \")\n",
    "    print(f\"===============================\\n\")\n",
    "    print(f\"Image Path: {img_path}\\n\")\n",
    "    \n",
    "    # Upload the image to Gemini\n",
    "    myfile = genai.upload_file(img_path)\n",
    "    \n",
    "    # Create the detailed prompt\n",
    "    detailed_prompt = (\n",
    "        \"Please analyze the provided breast ultrasound image in the context of the accompanying video, which consists of a series of images that illustrate different characteristics. \"\n",
    "        \"Identify any features in the image that may indicate abnormal structures or tumors, taking into account the visual cues presented in the video. \"\n",
    "        \"Focus on qualitative differences, including the presence of irregular borders, echotexture variations, or hypoechoic regions, particularly in comparison to the typical patterns observed in the video. \"\n",
    "        \"Additionally, provide a medical description of any identified tumors, including their size and morphology when applicable. \"\n",
    "        \"Use the examples provided in the video to inform your analysis and classification:\\n\\n\" + example_prompt\n",
    "    )\n",
    "\n",
    "    # Generate content for the image using Gemini 1.5 model\n",
    "    result = model.generate_content([\n",
    "        myfile, \"\\n\\n\", detailed_prompt\n",
    "    ])\n",
    "    \n",
    "    # Output the result from the LLM in a structured format\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"      Results for Image: {img_path}      \")\n",
    "    print(f\"{'-' * 50}\")\n",
    "    print(f\"{result.text}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "    \n",
    "    # Display prompt details in a more readable format\n",
    "    print(\"Prompt Details:\")\n",
    "    print(result.usage_metadata)\n",
    "\n",
    "# Define the path to the folder containing malignant images\n",
    "folder_path = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/\"\n",
    "\n",
    "# Get a list of image files in the folder, excluding those with '_mask' in the filename\n",
    "image_files = [\n",
    "    os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "    if f.endswith('.png') and \"_mask\" not in f\n",
    "]\n",
    "\n",
    "# Pick 5 random images from the filtered list\n",
    "selected_images = np.random.choice(image_files, 5, replace=False)\n",
    "\n",
    "# Upload each selected image to Gemini 1.5 model and print the results\n",
    "for img_path in selected_images:\n",
    "    print(f\"===============================\")\n",
    "    print(f\"        Processing Image        \")\n",
    "    print(f\"===============================\\n\")\n",
    "    print(f\"Image Path: {img_path}\\n\")\n",
    "    \n",
    "    # Upload the image to Gemini\n",
    "    myfile = genai.upload_file(img_path)\n",
    "    \n",
    "    # Create the detailed prompt\n",
    "    detailed_prompt = (\n",
    "        \"Please analyze the provided breast ultrasound image in the context of the accompanying video, which consists of a series of images that illustrate different characteristics. \"\n",
    "        \"Identify any features in the image that may indicate abnormal structures or tumors, taking into account the visual cues presented in the video. \"\n",
    "        \"Focus on qualitative differences, including the presence of irregular borders, echotexture variations, or hypoechoic regions, particularly in comparison to the typical patterns observed in the video. \"\n",
    "        \"Additionally, provide a medical description of any identified tumors, including their size and morphology when applicable. \"\n",
    "        \"Use the examples provided in the video to inform your analysis and classification:\\n\\n\" + example_prompt\n",
    "    )\n",
    "\n",
    "    # Generate content for the image using Gemini 1.5 model\n",
    "    result = model.generate_content([\n",
    "        myfile, \"\\n\\n\", detailed_prompt\n",
    "    ])\n",
    "    \n",
    "    # Output the result from the LLM in a structured format\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"      Results for Image: {img_path}      \")\n",
    "    print(f\"{'-' * 50}\")\n",
    "    print(f\"{result.text}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    # Display prompt details in a readable format\n",
    "    print(\"Prompt Details:\")\n",
    "    print(result.usage_metadata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536c951-231f-46f7-8f5e-479a43105202",
   "metadata": {},
   "outputs": [],
   "source": [
    "429203418339\n",
    "AIzaSyCy6VBQEvEE6rrWanM4GVw31xWQStcb4Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fabc84b-6a78-4f17-a9cf-24a7d073c057",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyCy6VBQEvEE6rrWanM4GVw31xWQStcb4Z4\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ[\"AIzaSyCy6VBQEvEE6rrWanM4GVw31xWQStcb4Z4\"])\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0c68a3-0e52-44f6-baea-6650cc8e2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-cloud\n",
      "  Downloading google_cloud-0.34.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading google_cloud-0.34.0-py2.py3-none-any.whl (1.8 kB)\n",
      "Installing collected packages: google-cloud\n",
      "Successfully installed google-cloud-0.34.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "url = \"https://api.example.com/endpoint\"  # Gerçek endpoint'i kullanın\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(\"API anahtarı çalışıyor!\")\n",
    "else:\n",
    "    print(\"API anahtarı çalışmıyor. Hata kodu:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4555fd4d-bf46-4e10-ae6e-690dc49429a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.generative-ai.google.com', port=443): Max retries exceeded with url: /v1beta/generate (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000260EE7A0740>: Failed to resolve 'api.generative-ai.google.com' ([Errno 11001] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    197\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    199\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    200\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\socket.py:964\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    963\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    965\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    616\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000260EE7A0740>: Failed to resolve 'api.generative-ai.google.com' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.generative-ai.google.com', port=443): Max retries exceeded with url: /v1beta/generate (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000260EE7A0740>: Failed to resolve 'api.generative-ai.google.com' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain how AI works\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     17\u001b[0m }\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mdata, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Print the generated content\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:622\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.generative-ai.google.com', port=443): Max retries exceeded with url: /v1beta/generate (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000260EE7A0740>: Failed to resolve 'api.generative-ai.google.com' ([Errno 11001] getaddrinfo failed)\"))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set up your API key\n",
    "api_key = 'AIzaSyCy6VBQEvEE6rrWanM4GVw31xWQStcb4Z4'\n",
    "\n",
    "# Define the endpoint\n",
    "url = 'https://api.generative-ai.google.com/v1beta/generate'  # Example URL, check docs for real endpoint\n",
    "\n",
    "# Define the request headers and payload\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "data = {\n",
    "    \"prompt\": \"Explain how AI works\",\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "# Print the generated content\n",
    "if response.status_code == 200:\n",
    "    print(response.json())  # Or response.text if it's plain text\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce406159-db95-4e2c-a43d-2189656ec930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenza.chenni\\AppData\\Local\\Temp\\ipykernel_25100\\2069533148.py:10: DtypeWarning: Columns (104,148,155,163,164,174,176,177,178,188,190,191,192,204,211,216,218,219,220,230,232,261,262,385,420,422,433,450,453,455,461,474,476,478,479,481,483,488,489,493,495,530,533,535,545) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  matched_df = pd.read_csv('NON CANCER.csv')  # First sheet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "matched_df = pd.read_csv('NON CANCER.csv')  # First sheet\n",
    "merged_cancer = pd.read_csv('CANCER.csv')  # Second sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c5ee3b-c345-47c2-ba03-b3e12496612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AbsolutePath</th>\n",
       "      <th>RelativePath</th>\n",
       "      <th>InputFileName_x</th>\n",
       "      <th>StudyDate_x</th>\n",
       "      <th>StudyTime_x</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientBirthDate_x</th>\n",
       "      <th>PatientSex_x</th>\n",
       "      <th>PatientAge_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Ca_LVI</th>\n",
       "      <th>Ca_Nekroz</th>\n",
       "      <th>Ca_HG</th>\n",
       "      <th>Ca_NG</th>\n",
       "      <th>Ca_CerSinir</th>\n",
       "      <th>Ca_Mfokal</th>\n",
       "      <th>Ca_CERB2</th>\n",
       "      <th>Ca_ER</th>\n",
       "      <th>Ca_PR</th>\n",
       "      <th>Ca_Ki67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D:/cancercases\\duplicate\\Yeni klasör (119)\\FIL...</td>\n",
       "      <td>duplicate\\Yeni klasör (119)\\FILES\\FILE0008</td>\n",
       "      <td>FILE0008</td>\n",
       "      <td>20170622</td>\n",
       "      <td>122227</td>\n",
       "      <td>tc24023731192</td>\n",
       "      <td>19540731</td>\n",
       "      <td>F</td>\n",
       "      <td>062Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D:/cancercases\\TANILI\\Yeni klasör (24)\\FILES\\F...</td>\n",
       "      <td>TANILI\\Yeni klasör (24)\\FILES\\FILE0008</td>\n",
       "      <td>FILE0008</td>\n",
       "      <td>20170705</td>\n",
       "      <td>163145</td>\n",
       "      <td>4978</td>\n",
       "      <td>19620321</td>\n",
       "      <td>F</td>\n",
       "      <td>055Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Var</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D:/cancercases\\TANILI\\Yeni klasör (25)\\FILES\\F...</td>\n",
       "      <td>TANILI\\Yeni klasör (25)\\FILES\\FILE0000</td>\n",
       "      <td>FILE0000</td>\n",
       "      <td>20170510</td>\n",
       "      <td>155156</td>\n",
       "      <td>4607</td>\n",
       "      <td>19620720</td>\n",
       "      <td>F</td>\n",
       "      <td>054Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>D:/cancercases\\KIRMIZI_CD_NOKSAN\\Yeni klasör (...</td>\n",
       "      <td>KIRMIZI_CD_NOKSAN\\Yeni klasör (124)\\FILES\\FILE...</td>\n",
       "      <td>FILE0015</td>\n",
       "      <td>20181027</td>\n",
       "      <td>134215</td>\n",
       "      <td>2647</td>\n",
       "      <td>19550514</td>\n",
       "      <td>F</td>\n",
       "      <td>063Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>95</td>\n",
       "      <td>30</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D:/cancercases\\KIRMIZI_CD_NOKSAN\\Yeni klasör (...</td>\n",
       "      <td>KIRMIZI_CD_NOKSAN\\Yeni klasör (125)\\FILES\\FILE...</td>\n",
       "      <td>FILE0000</td>\n",
       "      <td>20161117</td>\n",
       "      <td>153152</td>\n",
       "      <td>tc39985632500</td>\n",
       "      <td>19530929</td>\n",
       "      <td>F</td>\n",
       "      <td>063Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...</td>\n",
       "      <td>TANILI\\Yeni klasör (86)\\FILES\\FILE0000</td>\n",
       "      <td>FILE0000</td>\n",
       "      <td>20100317</td>\n",
       "      <td>165719</td>\n",
       "      <td>DIT3322511857</td>\n",
       "      <td>19640215</td>\n",
       "      <td>F</td>\n",
       "      <td>046Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...</td>\n",
       "      <td>TANILI\\Yeni klasör (87)\\FILES\\FILE0000</td>\n",
       "      <td>FILE0000</td>\n",
       "      <td>20091218</td>\n",
       "      <td>153339</td>\n",
       "      <td>DIT4249747719</td>\n",
       "      <td>19630523</td>\n",
       "      <td>F</td>\n",
       "      <td>046Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Yapılmadı</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...</td>\n",
       "      <td>TANILI\\Yeni klasör (88)\\FILES\\FILE0001</td>\n",
       "      <td>FILE0001</td>\n",
       "      <td>20100122</td>\n",
       "      <td>123345</td>\n",
       "      <td>DIT3943605662</td>\n",
       "      <td>19440404</td>\n",
       "      <td>F</td>\n",
       "      <td>065Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...</td>\n",
       "      <td>TANILI\\Yeni klasör (89)\\FILES\\FILE0000</td>\n",
       "      <td>FILE0000</td>\n",
       "      <td>20090703</td>\n",
       "      <td>162623</td>\n",
       "      <td>184</td>\n",
       "      <td>19640409</td>\n",
       "      <td>F</td>\n",
       "      <td>045Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Yapılmadı</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...</td>\n",
       "      <td>TANILI\\Yeni klasör (9)\\FILES\\FILE0004</td>\n",
       "      <td>FILE0004</td>\n",
       "      <td>20180627</td>\n",
       "      <td>142502</td>\n",
       "      <td>3072$$$16588</td>\n",
       "      <td>19701020</td>\n",
       "      <td>F</td>\n",
       "      <td>047Y</td>\n",
       "      <td>...</td>\n",
       "      <td>Yok</td>\n",
       "      <td>Yok</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tek odak</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 578 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                       AbsolutePath  \\\n",
       "0            0  D:/cancercases\\duplicate\\Yeni klasör (119)\\FIL...   \n",
       "1            1  D:/cancercases\\TANILI\\Yeni klasör (24)\\FILES\\F...   \n",
       "2            2  D:/cancercases\\TANILI\\Yeni klasör (25)\\FILES\\F...   \n",
       "3            3  D:/cancercases\\KIRMIZI_CD_NOKSAN\\Yeni klasör (...   \n",
       "4            4  D:/cancercases\\KIRMIZI_CD_NOKSAN\\Yeni klasör (...   \n",
       "..         ...                                                ...   \n",
       "82          82  D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...   \n",
       "83          83  D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...   \n",
       "84          84  D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...   \n",
       "85          85  D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...   \n",
       "86          86  D:/cancercases\\TANI GÖRÜNTÜSÜZLER\\Yeni klasör ...   \n",
       "\n",
       "                                         RelativePath InputFileName_x  \\\n",
       "0          duplicate\\Yeni klasör (119)\\FILES\\FILE0008        FILE0008   \n",
       "1              TANILI\\Yeni klasör (24)\\FILES\\FILE0008        FILE0008   \n",
       "2              TANILI\\Yeni klasör (25)\\FILES\\FILE0000        FILE0000   \n",
       "3   KIRMIZI_CD_NOKSAN\\Yeni klasör (124)\\FILES\\FILE...        FILE0015   \n",
       "4   KIRMIZI_CD_NOKSAN\\Yeni klasör (125)\\FILES\\FILE...        FILE0000   \n",
       "..                                                ...             ...   \n",
       "82             TANILI\\Yeni klasör (86)\\FILES\\FILE0000        FILE0000   \n",
       "83             TANILI\\Yeni klasör (87)\\FILES\\FILE0000        FILE0000   \n",
       "84             TANILI\\Yeni klasör (88)\\FILES\\FILE0001        FILE0001   \n",
       "85             TANILI\\Yeni klasör (89)\\FILES\\FILE0000        FILE0000   \n",
       "86              TANILI\\Yeni klasör (9)\\FILES\\FILE0004        FILE0004   \n",
       "\n",
       "    StudyDate_x  StudyTime_x      PatientID  PatientBirthDate_x PatientSex_x  \\\n",
       "0      20170622       122227  tc24023731192            19540731            F   \n",
       "1      20170705       163145           4978            19620321            F   \n",
       "2      20170510       155156           4607            19620720            F   \n",
       "3      20181027       134215           2647            19550514            F   \n",
       "4      20161117       153152  tc39985632500            19530929            F   \n",
       "..          ...          ...            ...                 ...          ...   \n",
       "82     20100317       165719  DIT3322511857            19640215            F   \n",
       "83     20091218       153339  DIT4249747719            19630523            F   \n",
       "84     20100122       123345  DIT3943605662            19440404            F   \n",
       "85     20090703       162623            184            19640409            F   \n",
       "86     20180627       142502   3072$$$16588            19701020            F   \n",
       "\n",
       "   PatientAge_x  ... Ca_LVI Ca_Nekroz Ca_HG Ca_NG Ca_CerSinir  Ca_Mfokal  \\\n",
       "0          062Y  ...    Yok       Yok   2.0   2.0         5.0   Tek odak   \n",
       "1          055Y  ...    Yok       Var   2.0   2.0        15.0   Tek odak   \n",
       "2          054Y  ...    Yok       Yok   3.0   3.0         5.0   Tek odak   \n",
       "3          063Y  ...    Yok       Yok   2.0   2.0         4.0   Tek odak   \n",
       "4          063Y  ...    Yok       Yok   2.0   3.0        16.0   Tek odak   \n",
       "..          ...  ...    ...       ...   ...   ...         ...        ...   \n",
       "82         046Y  ...    Yok       Yok   1.0   1.0        10.0   Tek odak   \n",
       "83         046Y  ...    Yok       Yok   1.0   1.0        15.0   Tek odak   \n",
       "84         065Y  ...    Yok       Yok   3.0   3.0         4.0   Tek odak   \n",
       "85         045Y  ...    Yok       Yok   1.0   1.0        10.0   Tek odak   \n",
       "86         047Y  ...    Yok       Yok   3.0   3.0         3.0   Tek odak   \n",
       "\n",
       "     Ca_CERB2  Ca_ER  Ca_PR Ca_Ki67  \n",
       "0     Negatif     90     70    12.0  \n",
       "1     Pozitif     90     10    16.0  \n",
       "2     Pozitif      0      0    15.0  \n",
       "3     Negatif     95     30    25.0  \n",
       "4     Negatif     95    100    11.0  \n",
       "..        ...    ...    ...     ...  \n",
       "82    Negatif    100     70    13.0  \n",
       "83  Yapılmadı     90     90     NaN  \n",
       "84    Negatif    100     70    30.0  \n",
       "85  Yapılmadı    100    100     NaN  \n",
       "86    Negatif    100     40    70.0  \n",
       "\n",
       "[87 rows x 578 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80eb94d0-d48e-48b1-834a-098b63e9f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder_non_cancer = r'C:\\Users\\kenza.chenni\\Desktop\\acıbademsana\\non cancer'\n",
    "root_folder_cancer = r'C:\\Users\\kenza.chenni\\Desktop\\acıbademsana\\cancer'\n",
    "\n",
    "image_names_non_cancer = matched_df['InputFileName'].astype(str).tolist()\n",
    "image_paths_cancer = merged_cancer['AbsolutePath'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbc3d8-3a12-4b96-b7e3-be9a745a9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the full image path\n",
    "def get_image_path_from_subfolders(image_name, root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        if image_name in files:\n",
    "            return os.path.join(root, image_name)\n",
    "    return None  # Return None if the image is not found\n",
    "\n",
    "# Retrieve image paths for non-cancer and cancer images\n",
    "image_paths_non_cancer = [get_image_path_from_subfolders(name, root_folder_non_cancer) for name in image_names_non_cancer]\n",
    "image_paths_cancer = [get_image_path_from_subfolders(name, root_folder_cancer) for name in image_paths_cancer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad63992-a9ea-477d-82a7-8c34d06b0e81",
   "metadata": {},
   "source": [
    "2. Prepare the Data for Training\n",
    "Next, let's prepare the images for training a model. You need to load the images into memory and preprocess them for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3737287-1678-472c-b910-8da24dbb4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))  # Resize to the desired size (e.g., 224x224)\n",
    "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array / 255.0  # Normalize image data to [0, 1]\n",
    "\n",
    "# Load all images (non-cancer and cancer) and their labels\n",
    "X_non_cancer = np.array([load_and_preprocess_image(path) for path in image_paths_non_cancer if path is not None])\n",
    "X_cancer = np.array([load_and_preprocess_image(path) for path in image_paths_cancer if path is not None])\n",
    "\n",
    "# Combine data and create labels (0 for non-cancer, 1 for cancer)\n",
    "X = np.concatenate([X_non_cancer, X_cancer], axis=0)\n",
    "y = np.concatenate([np.zeros(len(X_non_cancer)), np.ones(len(X_cancer))], axis=0)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518aa9b-eab4-4109-909b-c552a404ff59",
   "metadata": {},
   "source": [
    "3. Build the CNN Model for Classification\n",
    "Now, let's build a simple Convolutional Neural Network (CNN) to classify the images as cancer or non-cancer. You can use this model or modify it further based on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20e3ad-2dc0-408f-b645-f04b1fe09b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "def build_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))  # Convolution layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Max pooling layer\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))  # Another convolution layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Max pooling layer\n",
    "    model.add(Flatten())  # Flatten the output for dense layers\n",
    "    model.add(Dense(128, activation='relu'))  # Dense layer with 128 units\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = build_cnn_model()\n",
    "\n",
    "# Train the model on the data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423beb0-eeb1-415a-a3e2-fb40554a4ca9",
   "metadata": {},
   "source": [
    "4. Applying Gemini Model for Image Analysis\n",
    "Once the model is trained, you can integrate the Gemini 1.5 API to analyze the results, especially if you want to use AI to analyze the images after training your own CNN. Here's how you can integrate the Gemini API for more advanced analysis.\n",
    "\n",
    "Install Gemini API:\n",
    "\n",
    "Make sure you have already authenticated with the Gemini API and configured it using the token as shown earlier in the script.\n",
    "Upload the Images to Gemini for Analysis:\n",
    "\n",
    "You can upload the images directly to the Gemini API for advanced text generation and analysis, as seen in the earlier parts of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1499f4-e2ac-429e-af6e-17124cfaa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Authenticate and upload image for analysis\n",
    "def analyze_with_gemini(image_path):\n",
    "    img_file = genai.upload_file(image_path)  # Upload the image to Gemini\n",
    "    prompt = f\"Please analyze the provided breast ultrasound image and classify it as cancerous or non-cancerous.\"\n",
    "    result = model.generate_content([img_file, \"\\n\\n\", prompt])  # Generate analysis\n",
    "    return result.text  # Output analysis result\n",
    "\n",
    "# Example: Analyze a sample image\n",
    "image_path = image_paths_cancer[0]  # Replace with your desired image path\n",
    "result = analyze_with_gemini(image_path)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
